{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianFourierProjection(nn.Module):\n",
    "    '''\n",
    "    time step 인코딩 가우시안 랜덤 피쳐\n",
    "    '''\n",
    "    def __init__(self, embed_dim, scale=30.):\n",
    "        super().__init__()\n",
    "\n",
    "        # initialization할때 랜덤으로 샘플링된 weights. (Fixed, not learnable)\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: x.shape: ?\n",
    "\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "    \n",
    "class Dense(nn.Module):\n",
    "    '''\n",
    "    Fully Connected Layer\n",
    "    '''\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 왜 마지막에 [..., 1, 1] 뒤에 2개 차원을 더 붙이지,,?\n",
    "        return self.dense(x)[..., None, None]\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "    '''\n",
    "    Time-Dependent score-based model\n",
    "    U-Net 기반.\n",
    "    '''\n",
    "    def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\n",
    "        ''' Init\n",
    "        \n",
    "        Args:\n",
    "            - marginal_prob_std: t를 입력으로 받아 perturbation kernel \n",
    "                p_{0t}(x(t) | x(0))의 표준편차 반환하는 함수\n",
    "            - channels: 피쳐맵 각 resolution 채널 수\n",
    "            - embed_dim: 가우시안 랜덤 피쳐 임베딩 차원 수\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        # 시간 임베딩 가우시안 랜덤 피쳐\n",
    "        self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "                                   nn.Linear(embed_dim, embed_dim))\n",
    "        \n",
    "        # Encoding: resolution decreases\n",
    "        self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\n",
    "        self.dense1 = Dense(embed_dim, channels[0])\n",
    "        self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "\n",
    "        self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\n",
    "        self.dense2 = Dense(embed_dim, channels[1])\n",
    "        self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "\n",
    "        self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\n",
    "        self.dense3 = Dense(embed_dim, channels[2])\n",
    "        self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "\n",
    "        self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\n",
    "        self.dense4 = Dense(embed_dim, channels[3])\n",
    "        self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\n",
    "\n",
    "        # Decoding: resolution increases\n",
    "        self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\n",
    "        self.dense5 = Dense(embed_dim, channels[2])\n",
    "        self.tgnorm4 = nn.GroupNorm(32, num_channels=[2])\n",
    "\n",
    "        self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)\n",
    "        self.dense6 = Dense(embed_dim, channels[1])\n",
    "        self.tgnorm3 = nn.GroupNorm(32, num_channels=[1])\n",
    "\n",
    "        self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)\n",
    "        self.dense7 = Dense(embed_dim, channels[0])\n",
    "        self.tgnorm2 = nn.GroupNorm(32, num_channels=[0])\n",
    "\n",
    "        self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], 1, 3, stride=1)\n",
    "\n",
    "        # The Swish Activation Function (SELU)\n",
    "        self.act = lambda x: x * torch.sigmoid(x)\n",
    "        self.marginal_prob_std = marginal_prob_std\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # 시간 t를 가우시안 랜덤 피쳐에 임베딩\n",
    "        embed = self.act(self.embed(t))\n",
    "\n",
    "        # Encoding\n",
    "        h1 = self.act(self.gnorm1(self.conv1(x) + self.dense1(embed)))\n",
    "        h2 = self.act(self.gnorm2(self.conv2(h1) + self.dense2(embed)))\n",
    "        h3 = self.act(self.gnorm3(self.conv3(h2) + self.dense3(embed)))\n",
    "        h4 = self.act(self.gnorm4(self.conv4(h3) + self.dense4(embed)))\n",
    "\n",
    "        # Decoding\n",
    "        h = self.act(self.tgnorm4(self.tconv4(h4) + self.dense5(embed)))\n",
    "        h = self.act(self.tgnorm3(self.tconv3(torch.cat([h, h3], dim=1)) + self.dense6(embed)))\n",
    "        h = self.act(self.tgnorm2(self.tconv3(torch.cat([h, h2], dim=1)) + self.dense7(embed)))\n",
    "        h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "        h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{alignat}{1}\n",
    "dx = \\sigma^t dw, ~ t\\in [0, 1]\\\\\n",
    "p_{0t}(x(t)|x(0)) = N\\left( x(t); x(0), \\frac 1 {2\\log\\sigma} (\\sigma^{2t} -1 )\\mathbf{I}\\right)\n",
    "\\end{alignat}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "sigma = 25. \n",
    "\n",
    "def marginal_prob_std(t, sigma):\n",
    "    '''Compute the mean and standard deviation of $p_{0t}(x(t)|x(0))$\n",
    "\n",
    "    Args:\n",
    "        - t: time step vector\n",
    "        - sigma: SDE에서 sigma\n",
    "    \n",
    "    Returns:\n",
    "        - standard deviation of transition probability distribution p_0t\n",
    "    \n",
    "    '''\n",
    "    t = torch.tensor(t, device=device)\n",
    "    # cf. Eq(2)\n",
    "    return torch.sqrt((sigma ** (2 * t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "    '''Compute the diffusion coeff g(t): sigma^t\n",
    "\n",
    "    Args:\n",
    "        - t: time step vector\n",
    "        - sigma: SDE sigma\n",
    "\n",
    "    Returns:\n",
    "        - g(t)\n",
    "    '''\n",
    "    return torch.tenosr(sigma**t, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_prob_std = partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff = partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "$s_\\theta$가 학습해야하는 파라미터의 손실(목적)함수는 아래와 같다.\n",
    "$$\n",
    "\\tag{3} \\theta^* = \\argmin_\\theta \\Bbb{E}_{t\\sim \\mathcal{U}(0,T)}[\\lambda(t)\\Bbb{E}_{x \\sim p_0} \\Bbb{E}_{x(t) \\sim p_{0t}}[||s_\\theta(x(t),t) - \\nabla_x \\log p_{0t}(x(t) | x(0))||_2^2]] \n",
    "$$\n",
    "\n",
    "이때, 우리가 설정한 SDE 기준으로 transition probability distribution $p_{0t}$는 아래와 같이\n",
    "\n",
    "정규 분포 꼴로 나타나게 된다.\n",
    "$$\n",
    "\\tag{4} p_{0t}(x(t)|x(0)) = \\mathcal{N}\\left(x(t);x(0),\\Sigma^2\\right)\\\\\n",
    "\\text{where}~~~ \\Sigma^2 = \\frac 1 {2\\log\\sigma}(\\sigma^{2t}-1)\\mathbf{I}\\\\\n",
    "p_{0t}(x(t) | x(0)) = \\frac {1} {\\sqrt{2\\pi\\Sigma^2}}\\exp\\left(-\\frac {(x(t) - x(0))^2} {2\\Sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "정규 분포에 로그를 씌우고, 미분하게 되면 아래와 같은 간단한 형태의 수식을 얻을 수 있다.\n",
    "\n",
    "$$\n",
    "\\log p_{0t}(x(t) | x(0)) = -\\frac {(x(t) - x(0))^2} {2\\Sigma^2} - \\log \\sqrt{2\\pi\\Sigma^2}\\\\\n",
    "\\tag{5} \\nabla_{x(t)} \\log p_{0t}(x(t)|x(0)) = - \\frac {x(t)-x(0)} {\\Sigma^2}\n",
    "$$\n",
    "\n",
    "$\\Sigma^2$를 대입해준다. (cf. Eq.4)\n",
    "$$\n",
    "\\tag{6} \\nabla_{x(t)} \\log p_{0t}(x(t)|x(0)) = - \\frac {x(t) - x(0)} {(\\sigma^{2t} - 1)}2\\log\\sigma \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf. Eq(3)\n",
    "def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
    "    '''The loss function for training score-based generative models. (objectives)\n",
    "\n",
    "    Args:\n",
    "        - model: Pytorch Model instance (time-dependent, score-based model e.g. U-net)  \n",
    "        - x: A mini-batch of training data.\n",
    "        - marginial_prob_std: perturbed distribution의 표준편차를 리턴하는 함수\n",
    "        - eps: A tolerance value for numerical stability\n",
    "    '''\n",
    "    # random t from Uniform distribution\n",
    "    # eps: t ∈ [0, 1] -> t ∈ [eps, 1]\n",
    "    random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps\n",
    "    \n",
    "    # random standard noraml distribution(SND) noise\n",
    "    z = torch.randn_like(x)\n",
    "\n",
    "    # t에서 p_0t의 std\n",
    "    std = marginal_prob_std(random_t)\n",
    "    \n",
    "    # x(0) -> x(t)\n",
    "    perturbed_x = x + z * std[:, None, None, None]\n",
    "    \n",
    "    # s_theta(x(t), t) ~= ∇logp(x(t)|x(0))\n",
    "    score = model(perturbed_x, random_t)\n",
    "    loss = torch.mean(torch.sum((score * std[:, None, None, None] + z) ** 2, dim= (1,2,3)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6054, 0.4844, 0.2440, 0.4463, 0.8068]),\n",
       " tensor([0.5615, 0.4271, 0.1600, 0.3848, 0.7853]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt = torch.rand(5)\n",
    "rt * (1. - 1e-1) + 1e-1, rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

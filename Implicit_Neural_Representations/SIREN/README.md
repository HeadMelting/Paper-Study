# Summary
[youtube](https://youtu.be/Q5g3p9Zwjrk?si=cxo0uor27dB-Pu8R)

Implicit Neural Representations: ì–´ë– í•œ ì‹ í˜¸(ì´ë¯¸ì§€, ì˜ìƒ, ìŒì„± ë“±)ë¥¼ ì¸ê³µ ì‹ ê²½ë§ìœ¼ë¡œ í•™ìŠµëœ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•œ ìˆ˜ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ ì—°ì†ëœ ê³µê°„ì— ë‚˜íƒ€ë‚¸ë‹¤? - pros: ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì´ë©° ê·¸ë¦¬ë“œ í•´ìƒë„ì— ë¬´ê´€í•¨. - limitations: ì‹ í˜¸ë¥¼ ê³ ì°¨ì› ë¯¸ë¶„ìœ¼ë¡œ ë‚˜íƒ€ë‚´ì•¼í•˜ëŠ”ë°, representationì´ ì™„ë²½í•˜ì§€ ì•ŠìŒ (ì •ë³´ ì†ì‹¤?)

Previous works

- ë§ì€ ì„ í–‰ ì—°êµ¬ì—ì„œëŠ” ReLU-MLPë¥¼ ì´ìš©í–ˆëŠ”ë°, ReLUëŠ” 2ì°¨ ë¯¸ë¶„ì´ ì™„ì „íˆ 0ì´ê¸° ë•Œë¬¸ì—, í•œê³„ê°€ ì¡´ì¬í•¨.
- Periodic nonlinearities: ì£¼ê¸°ë¥¼ ê°–ëŠ” í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œ ì„ í–‰ ì—°êµ¬ë“¤
  - í‘¸ë¦¬ì— ë³€í™˜ì„ mimicí•œ ì—°êµ¬ë„ ì¡´ì¬
  - ê·¼ë° ì´ ì£¼ê¸°ë¥¼ ê°–ëŠ” í™œì„±í™” í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ INRs ìª½ ì—°êµ¬í•œ í˜ì´í¼ëŠ” ë³„ë¡œ ë§ì§€ ì•Šì•˜ë‚˜ë´„

## SIREN Formula

$$F(\rm x, \Phi, \nabla_x\Phi, \nabla_x^2\Phi, \dots) = 0, ~~ \Phi: \rm x \mapsto \Phi(\rm x) ~~~~~~~~~~~~~~~~~~\cdots(1)$$

ì‹œ-ê³µê°„ ì¢Œí‘œ xì™€, xë¥¼ $\Phi(\rm x)$ì— ë§¤í•‘í•˜ëŠ” í•¨ìˆ˜ $\Phi$ì˜ ë¯¸ë¶„ë“¤ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ 0ì„ ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜ Fë¥¼ ì°¾ëŠ”ë‹¤ëŠ” ê²ƒ -> ì‹¤ì œ signalì„ ì¸ê³µì‹ ê²½ë§ í•™ìŠµì„ í†µí•´ í•™ìŠµëœ $\Phi$ë¥¼ ì´ìš©í•´ì„œ ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒ.

$$\rm{find}~\Phi( \rm x) ~~ \rm{subject~~to~~} \cal{C}_m(a(\rm{x}), \Phi(\rm x), \nabla \Phi(\rm x), ...) = 0,~~\forall \rm x \in \Omega_m,~~m = 1, ...,M ~~~~~~~~~~~~ \cdots (2) $$

$$\cal{L} = \int_{\Omega} \sum_{m=1}^M 1_{\Omega_m} (\rm x) \|\cal{C}_m(a(\rm x), \Phi(\rm x) \nabla\Phi(\rm x), ... ) \| \cal{d}\rm x ~~~~~~~~~~~~~ \cdots(3)$$

$$\tilde{{\cal{L}}} = \sum_{i \in D} \sum_{m=1}^M \|\cal C_m (a(\rm x_i), \Phi (\rm x_i), \nabla \Phi(\rm X_i), \dots)\| ~~~~~~~~ \cdots (3.1)$$


(2) Mê°œì˜ constrain ì„ ë§Œì¡±í•˜ëŠ” $\phi$ë¥¼ ì°¾ëŠ” ê²ƒì„ ì¸ê³µ ì‹ ê²½ë§ ëª¨ë¸ì˜ ëª©í‘œë¡œ ì„¤ì •í•  ìˆ˜ ìˆìœ¼ë©°, ì†ì‹¤ í•¨ìˆ˜ë¥¼ (3)ê³¼ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. ì‹¤ì œë¡œ ëª¨ë¸ì„ í•™ìŠµí•  ë•Œì—ëŠ” indicator function $1_{\Omega_m}$ì„ ì‚¬ìš©í•˜ê¸° ë³´ë‹¤, ì‹¤ì œë¡œ $\Omega$ì— ì†í•˜ëŠ” ë°ì´í„°ì…‹ì—ì„œ ìƒ˜í”Œë§í•˜ë©°, ì´ë¥¼ í†µí•´ ì†ì‹¤í•¨ìˆ˜ë¥¼ (3.1)ì™€ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

### Periodic Activations for Implicit Neural Representations

$$\Phi(\rm x) = \bf W_n \phi_{n-1} \\circ \phi_{n-1} \circ\cdots\circ\phi_0)(\rm x) + \rm b_n,~~~\rm X_i \mapsto \phi_i(\rm x_i) = \sin(\bf{W}_i\rm x_i + \rm b_i) ~~~~~~~~ \cdots (4) $$

$\phi_i$ëŠ” ì¸ê³µì‹ ê²½ë§ì˜ ië²ˆì§¸ ë ˆì´ì–´ë¥¼ ì˜ë¯¸í•˜ê³ , ìœ„ ì‹ ê²½ë§ì€ siní•¨ìˆ˜ë¥¼ activation functionìœ¼ë¡œ ì‚¬ìš©í•œ SIRENì˜ êµ¬ì¡°ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ê¸°ë³¸ì ìœ¼ë¡œëŠ” fully connected layerì¸ ëª¨ìŠµì„.

> **ğŸ’¡NOTE**: `SIREN`ì˜ ë„í•¨ìˆ˜ë„ ë§ˆì°¬ê°€ì§€ë¡œ `SIREN`ì´ë‹¤. ì´ ì¸ê³µ ì‹ ê²½ë§ ìì²´ë¥¼ ë¯¸ë¶„í•˜ê²Œ ë˜ë©´, ê·¸ëŒ€ë¡œ SIRENì„. sineì˜ ë¯¸ë¶„ì€ cosine ì´ì§€ë§Œ, phase-shifted ëœ sineìœ¼ë¡œ ë³¼ ìˆ˜ ìˆê³ , ê²°ê³¼ì ìœ¼ë¡œ SIRENì´ ê·¸ëŒ€ë¡œ ìœ ì§€ë¨.

### A Simple Example: Fitting an image
2ì°¨ì› ì´ë¯¸ì§€ì˜ ìœ„ì¹˜ ì¢Œí‘œ $\rm x$(r, c)ë¥¼ ì´ìš©í•´ì„œ ê·¸ ìœ„ì¹˜ì˜ ìƒ‰ìƒ $f(\rm x_i)~\Bbb R^3$ (RGB)ì„ ì°¾ëŠ” í•¨ìˆ˜ $\Phi : \Bbb R^2 \mapsto \Bbb R^3, ~ \rm x \mapsto \Phi(\rm x)$ì„ ë§Œì¡±í•˜ëŠ” í•¨ìˆ˜ë¥¼ í•™ìŠµì‹œí‚¨ë‹¤ê³  ìƒê°í•´ë³´ì. ì´ë•Œ ë°ì´í„°ëŠ” $D = \{ ( \rm x_i, f( \rm x_i))\}$ì´ë‹¤. ì´ë•Œ, ì¸ê³µ ì‹ ê²½ë§ì˜ ì œì•½(ì¡°ê±´)ì¸ $C$ëŠ” $\Phi$ê°€ `ì´ë¯¸ì§€ ì¢Œí‘œ`ë¥¼ ë°›ì•„ì„œ `ì´ë¯¸ì§€ ìƒ‰ìƒ`ì„ ì¶œë ¥í•˜ê²Œ ë§Œë“ ë‹¤. ì´ ì œì•½ì€ $C(f(\rm x_i), \Phi(\rm x)) = \Phi(\rm x_i) - f(\rm x_i)$ë¡œ ë‚˜íƒ€ë‚¼ìˆ˜ ìˆìœ¼ë©°, 

ë”°ë¼ì„œ `ì†ì‹¤í•¨ìˆ˜` $\tilde{\cal L} = \sum_i \|\Phi(\rm x_i) - \cal f(\rm x_i)\|^2$ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

## Initialization
> (4)ì—ì„œ ì–¸ê¸‰í•œ ëª¨ë¸ êµ¬ì¡°ë¥¼ ë³´ë©´, ê¸°ë³¸ì ìœ¼ë¡œ Fully connected layerì˜ í˜•íƒœë¡œ, ê°€ì¤‘í•©ì— í™œì„±í™” í•¨ìˆ˜ë¥¼ í†µê³¼ì‹œí‚¨ ê¼´ì´ë‹¤. `ê°€ì¤‘ì¹˜(W)`ë¥¼ **Uniform distribution**ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ê³ , `ì…ë ¥(X)`ê°€ **arcsine distribution**ì¼ë•Œ, `ê°€ì¤‘í•©` ($\rm w^T\rm x$)ëŠ” **Normal distribution**ì´ ëœë‹¤ê³  ì¦ëª…í•¨. ë§ˆì§€ë§‰ìœ¼ë¡œ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥´ëŠ” ê°€ì¤‘í•©ì„ siní•¨ìˆ˜ì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì„ ê²½ìš°, `ì¶œë ¥`$\sin(\rm w^T \rm x)$ì€ **arcsine distribution**ì´ ë˜ì–´, ì…ë ¥ê³¼ ì¶œë ¥ì˜ ë¶„í¬ í˜•íƒœê°€ ë™ì¼í•˜ê²Œ ëœë‹¤.

#### ë” ìì„¸íˆ ë‹¤ë£¨ê¸° ì „ì—, `supplement`ì—ì„œ ì œì‹œí•œ ìœ„ ê°€ì •ì˜ ì¦ëª…ë¶€í„° ì•Œì•„ë³´ì.
----

#### Definition 1.1
*The arcsine distribution is defined for a random variable* $X$ *by its cumulative distribution function (CDF)* $F_{\rm X}$ *such as:*
$$X \thicksim \rm{Arcsin}(a,b), \rm{with} ~\it{CDF}:~F_{X}(x) = \frac 2 \pi \arcsin(\sqrt\frac {x-a} {b-a}), \rm{with} ~ b > a$$

#### Lemma 1.1
*Given* $X \thicksim U(-1, 1)$ *and* $Y = \sin(\frac \pi 2 X)$ *we have* $Y \thicksim \rm{Arcsin}(-1, 1)$

***Proof***. $X \thicksim U(-1, 1)$ ì¸ xì— ëŒ€í•´ì„œ, [-1, 1] êµ¬ê°„ì—ì„œ í™•ë¥  ë°€ë„ í•¨ìˆ˜(pdf) $\cal f(x) = \frac 1 2$ë¡œ ì •ì˜ëœë‹¤. ë”°ë¼ì„œ, ëˆ„ì  í™•ë¥  ë¶„í¬ í•¨ìˆ˜ê°€ $F_{\rm X}(x) = \Bbb{P}(\rm X \leq x) = \frac 1 2 x + \frac 1 2$ ì„ì€ ì‰½ê²Œ ì•Œ ìˆ˜ ìˆë‹¤. <br>
ìš°ë¦¬ëŠ” siní•¨ìˆ˜ë¥¼ í†µê³¼í•œ ì¶œë ¥ ê°’ì¸ $Y = \sin(\frac \pi 2 \rm X)$ì˜ ë¶„í¬ê°€ ì–´ë–»ê²Œ ë˜ëŠ”ì§€ ì•Œì•„ë³´ê³ ì í•œë‹¤.
$$F_Y(y) = \Bbb{P}(\sin(\frac \pi 2 X) \leq y) = \Bbb P (X \leq \frac 2 \pi \arcsin y) = F_X(\frac 2 \pi \arcsin y)$$

$$F_Y(y) = F_X(\frac 2 \pi \arcsin y) =\frac 1 \pi \arcsin y + \frac 1 2 ~~~~~\because F_X(x) = \frac 1 2 x + \frac 1 2$$

- pdf: $\frac d {df} F_Y(y) = \frac 1 \pi \frac 1 {\sqrt1 - y^2}$
> **ğŸ’¡NOTE**: Arcsine distributionì˜ ëˆ„ì  ë¶„í¬ í•¨ìˆ˜(CDF)ëŠ” $F(x) = \frac 2 \pi \arcsin(\sqrt x) = \frac {\arcsin(2x - 1)}{\pi} + \frac 1 2$ ì´ë‹¤. ì´ë•Œ, xëŠ” êµ¬ê°„ [0, 1]ì—ì„œ ë§Œì¡±í•˜ëŠ”ë°, ìœ„ $F_Y(y)$ì˜ ê²½ìš° **Arcsine distribution**ì˜ ëˆ„ì  ë¶„í¬ í•¨ìˆ˜ì™€ ë™ì¼í•œ í˜•íƒœë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, $0 < x < 1$ ì¸ë°, $y = 2x -1$ ì´ë¯€ë¡œ, $-1 < y< 1$ ì—ì„œ **Arcsine** ë¶„í¬ë¥¼ ë”°ë¥¸ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.


#### Lemma 1.2
*The variance of* $mX + n$ with $X$ *a random variable and* $m \in \Bbb R^+_{/0}, n \in \Bbb R$ *is* $\rm{Var}[mX+n] = m^2\rm{Var}[X]$

***Proof***. ì„ì˜ì˜ í™•ë¥  ë²ˆìˆ˜ê°€ ì—°ì†ëœ í™•ë¥  ë°€ë„ í•¨ìˆ˜ $f_X$ë¥¼ ë”°ë¥¸ë‹¤ê³  í• ë•Œ, <br/>ê¸°ëŒ€ê°’ì€ $\rm E[X] = \int_{-\infty}^{\infty} \cal f_X(x)dx$ ë¡œ ì •ì˜ë˜ë©°, <br/>ë¶„ì‚°ì€ $\rm{Var}[X] = \rm E[(X - \rm E[X])^2] = \rm E[X^2] - \rm E[X]^2$ë¡œ ì •ì˜ëœë‹¤.

**ë”°ë¼ì„œ**, $\rm{Var}[mX + n] = \rm E[(mX + n)^2] - \rm E[mX + n]^2 = \rm E[m^2X^2 + 2mnX + n^2] - (m\rm E[X] +n)^2 = m^2(\rm E[X^2] - \rm E[X]^2) = m^2\rm{Var}[X]$

#### Lemma 1.3
*The variance of* $X \thicksim \rm {Arcsin}(a,b)$ is $\rm{Var}[X] = \frac 1 8 (b-a)^2$

***Proof.*** $Z \thicksim \rm {Arcsin}(0,1)$ ì´ë©´, $\rm{Var}[Z] = \frac 1 8$ì´ê³ , $\rm E[Z] = \frac 1 2$ ì„ì„ ê³„ì‚°ì„ í†µí•´ êµ¬í•  ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³ , $\rm Var[Z] = \rm E[Z^2] - \rm E[Z]^2 = \rm E[Z^2] - \frac 1 4$ì„ì„ êµ¬í•  ìˆ˜ ìˆë‹¤. <br/>ì¦‰ ë¶„ì‚°ì„ êµ¬í•˜ê¸° ìœ„í•´ì„ , $Z^2$ì˜ ê¸°ëŒ€ê°’ì„ êµ¬í•˜ë©´ ëœë‹¤.

$$ \rm E[Z^2] = \cal \int_0^1 z^2 \cdot \frac 1 {\pi\sqrt{z(1-z)}}dz = \frac 2 \pi \int_0^1 \frac {t^4}{\sqrt{1-t^2}} dt = \frac 2 \pi \int_0^{\frac \pi 2} \sin^4  u~du = \frac 3 8$$

- **ì¹˜í™˜ ê³¼ì •**
    1. $z = t^2, ~ dz = 2t$
    2. $t = \sin(u), dt = \cos(u) du$



$X = mZ +n $ì´ê³ , $n = a, m = b- a$ ì´ë©´, $X \thicksim \rm{Arcsin}(m\cdot 0 + n, m\cdot 1 + n) = \rm{Arcsin}(a,b)$

$X \thicksim \rm{Arcsin}(a,b)$ ì´ê³  $Z \thicksim \rm{Arcsin}(0, 1)$ ì´ë¼ê³  í•˜ì.<br/>
ìœ„ì—ì„œ  $X \thicksim \rm{Arcsin}(\alpha, \beta)$ ì¼ ê²½ìš°, $X$ì˜ ì„ í˜• ì¡°í•©ì¸ $mX + n \thicksim \rm{Arcsin}(\alpha m + n, \beta m + n)$ì„ì„ ì¦ëª… í–ˆë‹¤. (Lemma 1.1)<br/>
$X = mZ + n$ ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìœ¼ë©°, ì´ë•Œ, $X = mZ + n \thicksim \rm{Arcsin}(0 \cdot m + n, 1 \cdot m + n) = \rm{Arcsin}(a,b)$ ì„ìœ¼ë¡œ

$$0 \cdot m + n = a ~~~~\therefore n = a \\ 1 \cdot m + n = b ~~~~\therefore m = b - a$$

**ìµœì¢…ì ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì´ ì¦ëª…í•  ìˆ˜ ìˆë‹¤.** 
$$Var[Z] = \frac 1 8$$
$$m = b-a$$
$$\therefore \rm{Var}[X] = \rm{Var}[m\cdot Z + n] = m^2\rm{Var}[Z] =  (b-a)^2 \cdot \frac {1} {8}$$


#### [Lemma1.4](https://www.cs.cmu.edu/~cga/var/2281592.pdf)
*For tow independent random variables* $X$ *and* $Y$
$$\rm Var [X \cdot Y] = Var[X] \cdot Var[Y] + E[Y]^2 \cdot Var[X] + E[X]^2 \cdot Y$$

***Proof:*** 
  1. ë‘ í™•ë¥  ë³€ìˆ˜ $X$ì™€ $Y$ê°€ ë…ë¦½ì´ë¼ê³  ê°€ì •. ë¶„ì‚° ì •ì˜ ì‚¬ìš©.
  $$\text{Var} [X \cdot Y] = E[(X \cdot Y - E[X \cdot Y])^2] \cdots (1.1) \\
  E[X \cdot Y] = E[X] \cdot E[Y] \cdots (1.2)$$

  2. ë…ë¦½ì„±ì— ì˜í•´ ì „ê°œí•˜ë©´
  $$ \text{Var}[XY] = {E}[(XY - {E}[X] E[Y])^2] \\
  =  E[X^2Y^2 - 2XY E[X] E[Y] +  E[X]^2 E[Y]^2] \\
  =  E[X^2Y^2] - 2E[X]E[Y]E[XY] + E[X]^2E[Y]^2$$
  $$= E[X^2Y^2] - E[X]^2E[Y]^2 ~~~~ \cdots (2.1) \\ \because E[XY] = E[X]E[Y]$$

  3. ì „ê°œ 2
  $$E[X^2Y^2] = E[X^2]E[Y^2] ~~~~ \cdots (3.1)$$

  4. ë¶„ì‚° ê¸°ë³¸ ê³µì‹ ì‘ìš©
  $$ \text{Var}[X] = E[X^2] - E[X]^2 \\ \therefore E[X^2] = \text{Var}[X] + E[X]^2$$
  - $Y$ë„ ë§ˆì°¬ê°€ì§€, $(3.1)$ì— ëŒ€ì…í•˜ë©´
  5. (3.1)ì— ëŒ€ì… í›„ ì •ë¦¬
  $$E[X^2Y^2] = (\text{Var}[X] + E[X]^2)(\text{Var}[Y] + E[Y]^2) \\ 
  = \text{Var}[X]\text{Var}[Y] + \text{Var}[X]E[Y]^2 + E[X]^2\text{Var}[Y] + E[X]^2E[Y]^2 ~~~ \cdots (5.1)$$

6. (2.1)ì— ëŒ€ì…í•˜ì—¬ ì™„ì„±
$$\text{Var}[XY] = E[X^2Y^2]-E[X]^2E[Y]^2\\
= \text{Var}[X]\text{Var}[Y] + \text{Var}[X]E[Y]^2 + E[X]^2\text{Var}[Y] ~~~~ \because (5.1) $$

#### [Theorem 1.5](https://www.cs.toronto.edu/~yuvalf/CLT.pdf)
*Central Limit Theorem with Lindeberg's sufficient condition. Let* $X_k, k\in \Bbb N$ *be independent random variables with expected values* $E[X_k] = \mu_k$ *and variances* $\text{Var}[X_k] = \sigma_k$, *Posing* $s^2_n = \sum_{k=1}^n \sigma_k^2$. *If the* $X_k$ *satisfy the Lindenberge condition:*
$$\lim_{n \rarr \infty} \frac 1 {s^2_n} \sum^n_{k=1} E[(X_k - \mu_k)^2 \cdot 1([X_k - \mu_k] > \epsilon s_n)] = 0$$


- Central limit theorem: ì„ì˜ì˜ í™•ë¥  ë³€ìˆ˜ë“¤ì˜ í•©ì€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥¸ ë‹¤ëŠ” ê²ƒì„.
- ìœ„ Lindeberge ì¡°ê±´ì„ ë”°ë¥¼ ë•Œ ì„±ë¦½í•˜ë©°, ìœ„ ì¡°ê±´ì—ì„œëŠ” indicatorë¥¼ ì‚¬ìš©í•´ì„œ ë„ˆë¬´ í° ì´ìƒì¹˜ê°€ ë¶„ì‚°ì— ì§€ë‚˜ì¹˜ê²Œ ê°œì…í•˜ì§€ ì•Šë„ë¡ ë°©ì§€í•œë‹¤. 

$$\forall \epsilon > 0; S_n = \frac 1 {s_n} \sum_{k=1}^n(X_k - \mu_k) $$
- ëª¨ë“  ì–‘ì˜ ì…ì‹¤ë¡ ì— ëŒ€í•´ì„œ, ìœ„ $S_n$ì€ nì´ ë¬´í•œëŒ€ë¡œ ê°ˆë•Œ, `í‘œì¤€ ì •ê·œ ë¶„í¬`ì— ìˆ˜ë ´í•˜ê²Œ ëœë‹¤.

- ì¦ëª…ì€ ë„˜ì–´ê°€ë„ë¡ í•¨.

#### Lemma 1.6
*Given a Gaussian distributed random variable* $X \thicksim N(0,1)$ *and* $Y = \sin{\frac \pi 2 X}$ *we have* $Y \thicksim \text{Arcsin}(-1, 1)$

[<img src="./imgs/lemma_fig1.png" height="200"/>](./imgs/lemma_fig1.png)

***Proof.*** 
$X \thicksim N(\mu, \sigma^2)$ì˜, `í™•ë¥  ë°€ë„ í•¨ìˆ˜(pdf)`ì™€ `ëˆ„ì  í™•ë¥  í•¨ìˆ˜(cdf)`ëŠ” ì•„ë˜ ì™€ ê°™ë‹¤
$$\text{PDF} = \frac 1 {\sigma \sqrt{2\pi}} e^{-\frac 1 2 (\frac {x - \mu} \sigma)^2}$$
$$\text{CDF} = \Phi(\frac {x-\mu} \sigma)=\frac 1 2[1+\text{erf}(\frac {x - \mu} {\sigma \sqrt 2})]$$

> **Cumulative distribution function**
> - $\Phi(x) = \frac 1 {\sqrt{2\pi}} \int_{-\infty}^x e^{-{t^2}/2} dt$
> - Error function: $\text{erf}(x) = \frac 1 {\sqrt{\pi}} \int_{-x}^x e^{-t^2} dt$ 
>   - $N(0,0.5)$ì˜ êµ¬ê°„[-x,x] ì‚¬ì´ í™•ë¥ ê°’ì„ ë°˜í™˜


$X \thicksim N(0, 1)$ ì¼ë•Œ, ì•„ë˜ì™€ ê°™ì´ ê·¼ì‚¬í•  ìˆ˜ ìˆë‹¤ ($\alpha = 1.702, \beta=0.690$).
$$F_X(x) = \frac 1 2 + \frac 1 2 \text{erf}(\frac x {\sqrt 2}) \\
\approx (1 + \text{exp}(-\alpha \cdot x))^{-1} \\
\approx \frac 1 2 + \frac 1 2 \tanh(\beta \cdot x)
$$

|[<img src="./imgs/lemma_approx.png" width="400"/>](./imgs/lemma_approx.png) <br/>**Compare Approx** |[<img src="./imgs/lemma_erf.png" width="400"/>](./imgs/lemma_erf.png) <br/>**F(x)** 0.5 + 0.5*erf(x/sqrt(2)) |
|---|---|
|[<img src="./imgs/lemma_approx_logistic.png" width="400"/>](./imgs/lemma_approx_logistic.png) <br/>**logistic** (1 + exp(-1.702x))^-1|[<img src="./imgs/lemma_approx_tanh.png" width="400"/>](./imgs/lemma_approx_tanh.png)<br/>**tanh** 0.5 + 0.5*erf(x/sqrt(2))|

í™•ë¥  ë³€ìˆ˜ $Y \thicksim \sin (\frac \pi 2 X)$ ì˜ ëˆ„ì  í™•ë¥  ë¶„í¬ í•¨ìˆ˜(CDF)ë¥¼ ì°¾ì•„ë‚´ëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤. Lemma 1.1ê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ì ‘ê·¼í•´ì•¼í•˜ì§€ë§Œ, ì •ê·œ ë¶„í¬ëŠ” closed formì´ ì—†ë‹¤. ë”°ë¼ì„œ `í‘œì¤€ ì •ê·œ ë¶„í¬`ì˜ 99.7%ë¥¼ ì°¨ì§€í•˜ëŠ” êµ¬ê°„ [-3, 3]ì— ëŒ€í•´ì„œ ê·¼ì‚¬í•˜ê³ , ë‹¤ë¥¸ ë¶€ë¶„ì€ ë¬´ì‹œí•œë‹¤.

$$F_Y(y) = \Bbb P(\sin(\frac \pi 2 X) \leq y) = \Bbb P (X \leq \frac 2 \pi \arcsin y) \\

= F_X(\frac 2 \pi \arcsin y)$$
-- ëª¨ë¥´ê²Œë”° í˜ë“œë¼
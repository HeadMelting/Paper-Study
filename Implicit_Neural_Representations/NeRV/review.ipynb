{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from NeRV.model_nerv import CustomDataSet, Generator\n",
    "from NeRV.utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.vid = [None]\n",
    "args.scale = 1\n",
    "args.frame_gap = 1\n",
    "args.augment = 0\n",
    "args.dataset = 'bunny'\n",
    "args.test_gap = 1\n",
    "args.embed = '1.25_40'\n",
    "args.stem_dim_num = '512_1'\n",
    "args.fc_hw_dim = '9_16_26'\n",
    "args.expansion = 1\n",
    "args.reduction = 2\n",
    "args.strides = [5,2,2,2,2]\n",
    "args.num_blocks = 1\n",
    "args.norm = 'none'\n",
    "args.act = 'swish'\n",
    "args.lower_width = 96\n",
    "args.single_res = True\n",
    "args.conv_type = 'conv'\n",
    "args.workers = 4\n",
    "args.batchSize = 1\n",
    "args.not_resume_epoch = True\n",
    "args.epochs = 300\n",
    "args.cycles = 1\n",
    "args.warmup = 0.2\n",
    "args.lr = 0.0005\n",
    "args.lr_type = 'cosine'\n",
    "args.lr_steps = []\n",
    "args.beta = 0.5\n",
    "args.loss_type = 'Fusion6'\n",
    "args.lw = 1.0\n",
    "args.sigmoid = True\n",
    "args.eval_only = False\n",
    "args.eval_freq = 50\n",
    "args.quant_bit = -1\n",
    "args.quant_axis = 0\n",
    "args.dump_images = False\n",
    "args.eval_fps = False\n",
    "args.prune_steps = [0.,]\n",
    "args.prune_ratio = 1.0\n",
    "args.manualSeed = 1\n",
    "args.init_method = 'tcp://127.0.0.1:9888'\n",
    "args.distributed = False\n",
    "args.debug = True\n",
    "args.print_freq = 50\n",
    "args.weight = 'None'\n",
    "args.overwrite = False\n",
    "args.outf = 'NeRV/bunny_ab'\n",
    "args.suffix = ''\n",
    "args.ngpus_per_node = 1\n",
    "\n",
    "\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(args.manualSeed)\n",
    "random.seed(args.manualSeed)\n",
    "\n",
    "if not os.path.isdir(args.outf):\n",
    "        os.makedirs(args.outf)\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "local_rank = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best_psnr, train_best_msssim, val_best_psnr, val_best_msssim = [torch.tensor(0) for _ in range(4)]\n",
    "is_train_best, is_val_best = False, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PE = PositionalEncoding(args.embed)\n",
    "args.embed_length = PE.embed_length\n",
    "model = Generator(embed_length=args.embed_length, stem_dim_num=args.stem_dim_num, fc_hw_dim=args.fc_hw_dim, expansion=args.expansion, \n",
    "        num_blocks=args.num_blocks, norm=args.norm, act=args.act, bias = True, reduction=args.reduction, conv_type=args.conv_type,\n",
    "        stride_list=args.strides,  sin_res=args.single_res,  lower_width=args.lower_width, sigmoid=args.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prune Model\n",
    "prune_net = args.prune_ratio < 1\n",
    "if prune_net:\n",
    "    raise NotImplementedError(\"Not Implemented Yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(vid=[None], scale=1, frame_gap=1, augment=0, dataset='bunny', test_gap=1, embed='1.25_40', stem_dim_num='512_1', fc_hw_dim='9_16_26', expansion=1, reduction=2, strides=[5, 2, 2, 2, 2], num_blocks=1, norm='none', act='swish', lower_width=96, single_res=True, conv_type='conv', workers=4, batchSize=1, not_resume_epoch=True, epochs=300, cycles=1, warmup=0.2, lr=0.0005, lr_type='cosine', lr_steps=[], beta=0.5, loss_type='Fusion6', lw=1.0, sigmoid=True, eval_only=False, eval_freq=50, quant_bit=-1, quant_axis=0, dump_images=False, eval_fps=False, prune_steps=[0.0], prune_ratio=1.0, manualSeed=1, init_method='tcp://127.0.0.1:9888', distributed=False, debug=True, print_freq=50, weight='None', overwrite=False, outf='NeRV/bunny_ab', suffix='', ngpus_per_node=1, embed_length=80)\n",
      " Generator(\n",
      "  (stem): Sequential(\n",
      "    (0): Linear(in_features=80, out_features=512, bias=True)\n",
      "    (1): SiLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=3744, bias=True)\n",
      "    (3): SiLU(inplace=True)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0): NeRVBlock(\n",
      "      (conv): CustomConv(\n",
      "        (conv): Conv2d(26, 650, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (up_scale): PixelShuffle(upscale_factor=5)\n",
      "      )\n",
      "      (norm): Identity()\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): NeRVBlock(\n",
      "      (conv): CustomConv(\n",
      "        (conv): Conv2d(26, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (up_scale): PixelShuffle(upscale_factor=2)\n",
      "      )\n",
      "      (norm): Identity()\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2-4): 3 x NeRVBlock(\n",
      "      (conv): CustomConv(\n",
      "        (conv): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (up_scale): PixelShuffle(upscale_factor=2)\n",
      "      )\n",
      "      (norm): Identity()\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (head_layers): ModuleList(\n",
      "    (0-3): 4 x None\n",
      "    (4): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      " Model Params: 3.201905M\n"
     ]
    }
   ],
   "source": [
    "## Get Model params and flops\n",
    "total_params = sum([p.data.nelement() for p in model.parameters()]) / 1e6\n",
    "params = sum([p.data.nelement() for p in model.parameters()]) / 1e6\n",
    "\n",
    "print(f'{args}\\n {model}\\n Model Params: {params}M')\n",
    "with open ('{}/rank0.txt'.format(args.outf), 'a') as f:\n",
    "    f.write(str(model) + '\\n' + f'Params: {params}M\\n')\n",
    "writer = SummaryWriter(os.path.join(args.outf, f'param_{total_params}M', 'tensorboard'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed model to gpu or parallel\n",
    "if args.distributed and args.ngus_per_node > 1:\n",
    "    raise NotImplementedError(\"Distributed model not implemented\")\n",
    "elif args.ngpus_per_node > 1:\n",
    "    raise NotImplementedError(\"Distributed model not implemented\")\n",
    "else:\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), betas=(args.beta, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.weight != 'None':\n",
    "    raise NotImplementedError(\"Resume From Weight Not Implemented\")\n",
    "\n",
    "## Resume from nodekl_latest\n",
    "checkpoint = None\n",
    "checkpoint_path = os.path.join(args.outf, 'model_latest.pth')\n",
    "if os.path.isfile(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    if prune_net:\n",
    "       raise NotImplementedError(\"Prune Not Implemented\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"=> Auto resume loaded checkpoint '{}' (epoch {})\".format(checkpoint_path, checkpoint['epoch']))\n",
    "else:\n",
    "    print(\"=> No resume checkpoint found at '{}'\".format(checkpoint_path))\n",
    "\n",
    "loc = 'mps:0'\n",
    "if checkpoint is not None:\n",
    "    args.start_epoch = checkpoint['epoch'] \n",
    "    train_best_psnr = checkpoint['train_best_psnr'].to(torch.device(loc))\n",
    "    train_best_msssim = checkpoint['train_best_msssim'].to(torch.device(loc))\n",
    "    val_best_psnr = checkpoint['val_best_psnr'].to(torch.device(loc))\n",
    "    val_best_msssim = checkpoint['val_best_msssim'].to(torch.device(loc))\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = transforms.ToTensor()\n",
    "DataSet = CustomDataSet\n",
    "train_data_dir = f'NeRV/data/{args.dataset.lower()}'\n",
    "val_data_dir = f'NeRV/data/{args.dataset.lower()}'\n",
    "\n",
    "train_dataset = DataSet(train_data_dir, img_transforms,vid_list=args.vid, frame_gap=args.frame_gap,  )\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset) if args.distributed else None\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batchSize, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler, drop_last=True, worker_init_fn=worker_init_fn)\n",
    "\n",
    "val_dataset = DataSet(val_data_dir, img_transforms, vid_list=args.vid, frame_gap=args.test_gap,  )\n",
    "val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset) if args.distributed else None\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batchSize,  shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True, sampler=val_sampler, drop_last=False, worker_init_fn=worker_init_fn)\n",
    "data_size = len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9525,  0.3045,  1.0000, -0.0059,  0.9210, -0.3895,  0.6272, -0.7789,\n",
       "           0.0620, -0.9981, -0.6502, -0.7597, -0.9951,  0.0993, -0.2652,  0.9642,\n",
       "           0.9443,  0.3292,  0.0266, -0.9996, -0.7303,  0.6832,  0.8539, -0.5205,\n",
       "          -0.4740,  0.8805, -0.8155, -0.5788, -0.3954, -0.9185, -0.9618, -0.2737,\n",
       "           0.7390,  0.6737, -0.5067,  0.8621,  0.7874,  0.6165, -0.4238,  0.9058,\n",
       "           0.5201, -0.8541, -0.9948,  0.1015,  0.9649,  0.2625,  0.0606,  0.9982,\n",
       "          -0.0758, -0.9971,  0.7709,  0.6370,  0.4534, -0.8913,  0.1959,  0.9806,\n",
       "          -0.9698,  0.2440, -0.9964, -0.0844,  0.8784,  0.4780, -0.9736, -0.2282,\n",
       "           0.6291, -0.7773, -0.9979, -0.0652, -0.4568,  0.8896, -0.5584,  0.8295,\n",
       "          -0.7377, -0.6752,  0.9685, -0.2489, -0.6497, -0.7602,  0.9951, -0.0990]]),\n",
       " tensor([0.4015]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(data_iter)\n",
    "data, norm_idx = batch\n",
    "PE(norm_idx), norm_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6272518154951441"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sin(0.4015 * (1.25)**3 * math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_dataloader, pe, local_rank, args):\n",
    "    # Model Quantization\n",
    "    if args.quant_bit != -1:\n",
    "        raise NotImplementedError(\"HuffmanCodec Not Implemented\")\n",
    "\n",
    "    psnr_list = []\n",
    "    msssim_list = []\n",
    "    if args.dump_images:\n",
    "        from torchvision.utils import save_image\n",
    "        visual_dir = f'{args.outf}/visualize'\n",
    "        print(f'Saving predictions to {visual_dir}')\n",
    "        if not os.path.isdir(visual_dir):\n",
    "            os.makedirs(visual_dir)\n",
    "\n",
    "    time_list = []\n",
    "    model.eval()\n",
    "    for i, (data,  norm_idx) in enumerate(val_dataloader):\n",
    "        if i > 10 and args.debug:\n",
    "            break\n",
    "        embed_input = pe(norm_idx)\n",
    "        if local_rank not in [0, None]:\n",
    "            raise NotImplementedError(\"Distributed Model not Implemented\")\n",
    "        else:\n",
    "            data,  embed_input = data.to(device=device, non_blocking=True), embed_input.to(device=device, non_blocking=True)\n",
    "\n",
    "        # compute psnr and msssim\n",
    "        fwd_num = 10 if args.eval_fps else 1\n",
    "        for _ in range(fwd_num):\n",
    "            # embed_input = embed_input.half()\n",
    "            # model = model.half()\n",
    "            start_time = datetime.now()\n",
    "            output_list = model(embed_input)\n",
    "            # torch.cuda.current_stream().synchronize()\n",
    "            time_list.append((datetime.now() - start_time).total_seconds())\n",
    "\n",
    "        # dump predictions\n",
    "        if args.dump_images:\n",
    "            for batch_ind in range(args.batchSize):\n",
    "                full_ind = i * args.batchSize + batch_ind\n",
    "                save_image(output_list[-1][batch_ind], f'{visual_dir}/pred_{full_ind}.png')\n",
    "                save_image(data[batch_ind], f'{visual_dir}/gt_{full_ind}.png')\n",
    "\n",
    "        # compute psnr and ms-ssim\n",
    "        target_list = [F.adaptive_avg_pool2d(data, x.shape[-2:]) for x in output_list]\n",
    "        psnr_list.append(psnr_fn(output_list, target_list))\n",
    "        msssim_list.append(msssim_fn(output_list, target_list))\n",
    "        val_psnr = torch.cat(psnr_list, dim=0)              #(batchsize, num_stage)\n",
    "        val_psnr = torch.mean(val_psnr, dim=0)              #(num_stage)\n",
    "        val_msssim = torch.cat(msssim_list, dim=0)          #(batchsize, num_stage)\n",
    "        val_msssim = torch.mean(val_msssim.float(), dim=0)  #(num_stage)        \n",
    "        if i % args.print_freq == 0:\n",
    "            fps = fwd_num * (i+1) * args.batchSize / sum(time_list)\n",
    "            print_str = 'Rank:{}, Step [{}/{}], PSNR: {}, MSSSIM: {} FPS: {}'.format(\n",
    "                local_rank, i+1, len(val_dataloader),\n",
    "                RoundTensor(val_psnr, 2, False), RoundTensor(val_msssim, 4, False), round(fps, 2))\n",
    "            print(print_str)\n",
    "            if local_rank in [0, None]:\n",
    "                with open('{}/rank0.txt'.format(args.outf), 'a') as f:\n",
    "                    f.write(print_str + '\\n')\n",
    "    model.train()\n",
    "\n",
    "    return val_psnr, val_msssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "total_epochs = args.epochs * args.cycles\n",
    "for epoch in range(args.start_epoch, total_epochs):\n",
    "    model.train()\n",
    "    epoch_start_time = datetime.now()\n",
    "    psnr_list = []\n",
    "    msssim_list = []\n",
    "\n",
    "    for i, (data, norm_idx) in enumerate(train_dataloader):\n",
    "        if i > 10 and args.debug:\n",
    "            break\n",
    "    \n",
    "        embed_input = PE(norm_idx)\n",
    "        data, embed_input = data.to(device), embed_input.to(device)\n",
    "\n",
    "        output_list = model(embed_input)\n",
    "        target_list = [F.adaptive_avg_pool2d(data, x.shape[-2:]) for x in output_list]\n",
    "        loss_list = [loss_fn(output, target, args) for output, target in zip(output_list, target_list)]\n",
    "        loss_list = [loss_list[i] * (args.lw if i < len(loss_list) - 1 else 1) for i in range(len(loss_list))]\n",
    "        loss_sum = sum(loss_list)\n",
    "        lr = adjust_lr(optimizer, epoch % args.epochs, i, data_size, args)\n",
    "        optimizer.zero_grad()\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute psnr and msssim\n",
    "        psnr_list.append(psnr_fn(output_list, target_list))\n",
    "        msssim_list.append(msssim_fn(output_list, target_list))\n",
    "        if i % args.print_freq == 0 or i == len(train_dataloader) - 1 :\n",
    "            train_psnr = torch.cat(psnr_list, dim=0)\n",
    "            train_psnr = torch.mean(train_psnr, dim=0)\n",
    "            train_msssim = torch.cat(msssim_list, dim = 0)\n",
    "            train_msssim = torch.mean(train_msssim.float(), dim = 0)\n",
    "            time_now_string = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "            print_str = '[{}] Rank:{}, Epoch[{}/{}], Step [{}/{}], lr:{:2e} PSNR: {}, MSSSIM: {}'.format(\n",
    "                time_now_string, 0, epoch+1, args.epochs, i+1, len(train_dataloader), lr,\n",
    "                RoundTensor(train_psnr, 2, False), RoundTensor(train_msssim, 4, False)\n",
    "            )\n",
    "            print(print_str)\n",
    "            if local_rank in [0, None]:\n",
    "                with open('{}/rank0.txt'.format(args.outf), 'a') as f:\n",
    "                            f.write(print_str + '\\n')\n",
    "\n",
    "        if local_rank in [0, None]:\n",
    "            h, w = output_list[-1].shape[-2:]\n",
    "            is_train_best = train_psnr[-1] > train_best_psnr\n",
    "            train_best_psnr = train_psnr[-1] if train_psnr[-1] > train_best_psnr else train_best_psnr\n",
    "            train_best_msssim = train_msssim[-1] if train_msssim[-1] > train_best_msssim else train_best_msssim\n",
    "            writer.add_scalar(f'Train/PSNR_{h}X{w}_gap{args.frame_gap}', train_psnr[-1].item(), epoch+1)\n",
    "            writer.add_scalar(f'Train/MSSSIM_{h}X{w}_gap{args.frame_gap}', train_msssim[-1].item(), epoch+1)\n",
    "            writer.add_scalar(f'Train/best_PSNR_{h}X{w}_gap{args.frame_gap}', train_best_psnr.item(), epoch+1)\n",
    "            writer.add_scalar(f'Train/best_MSSSIM_{h}X{w}_gap{args.frame_gap}', train_best_msssim, epoch+1)\n",
    "            print_str = '\\t{}p: current: {:.2f}\\t best: {:.2f}\\t msssim_best: {:.4f}\\t'.format(h, train_psnr[-1].item(), train_best_psnr.item(), train_best_msssim.item())\n",
    "            print(print_str, flush=True)\n",
    "            with open('{}/rank0.txt'.format(args.outf), 'a') as f:\n",
    "                f.write(print_str + '\\n')\n",
    "            writer.add_scalar('Train/lr', lr, epoch+1)\n",
    "            epoch_end_time = datetime.now()\n",
    "            print(\"Time/epoch: \\tCurrent:{:.2f} \\tAverage:{:.2f}\".format( (epoch_end_time - epoch_start_time).total_seconds(), \\\n",
    "                    (epoch_end_time - start).total_seconds() / (epoch + 1 - args.start_epoch) ))\n",
    "        \n",
    "        state_dict = model.state_dict()\n",
    "        save_checkpoint = {\n",
    "            'epoch': epoch+1,\n",
    "            'state_dict': state_dict,\n",
    "            'train_best_psnr': train_best_psnr,\n",
    "            'train_best_msssim': train_best_msssim,\n",
    "            'val_best_psnr': val_best_psnr,\n",
    "            'val_best_msssim': val_best_msssim,\n",
    "            'optimizer': optimizer.state_dict(),   \n",
    "        }    \n",
    "\n",
    "        if (epoch + 1) % args.eval_freq == 0 or epoch > total_epochs - 10:\n",
    "            val_start_time = datetime.now()\n",
    "            val_psnr, val_msssim = evaluate(model, val_dataloader, PE, local_rank, args)\n",
    "            val_end_time = datetime.now()\n",
    "        \n",
    "            if local_rank in [0, None]:\n",
    "                    # ADD val_PSNR TO TENSORBOARD\n",
    "                    h, w = output_list[-1].shape[-2:]\n",
    "                    print_str = f'Eval best_PSNR at epoch{epoch+1}:'\n",
    "                    is_val_best = val_psnr[-1] > val_best_psnr\n",
    "                    val_best_psnr = val_psnr[-1] if is_val_best else val_best_psnr\n",
    "                    val_best_msssim = val_msssim[-1] if val_msssim[-1] > val_best_msssim else val_best_msssim\n",
    "                    writer.add_scalar(f'Val/PSNR_{h}X{w}_gap{args.test_gap}', val_psnr[-1], epoch+1)\n",
    "                    writer.add_scalar(f'Val/MSSSIM_{h}X{w}_gap{args.test_gap}', val_msssim[-1], epoch+1)\n",
    "                    writer.add_scalar(f'Val/best_PSNR_{h}X{w}_gap{args.test_gap}', val_best_psnr, epoch+1)\n",
    "                    writer.add_scalar(f'Val/best_MSSSIM_{h}X{w}_gap{args.test_gap}', val_best_msssim, epoch+1)\n",
    "                    print_str += '\\t{}p: current: {:.2f}\\tbest: {:.2f} \\tbest_msssim: {:.4f}\\t Time/epoch: {:.2f}'.format(h, val_psnr[-1].item(),\n",
    "                        val_best_psnr.item(), val_best_msssim.item(), (val_end_time - val_start_time).total_seconds())\n",
    "                    print(print_str)\n",
    "                    with open('{}/rank0.txt'.format(args.outf), 'a') as f:\n",
    "                        f.write(print_str + '\\n')\n",
    "                    if is_val_best:\n",
    "                        torch.save(save_checkpoint, '{}/model_val_best.pth'.format(args.outf))\n",
    "\n",
    "        if local_rank in [0, None]:\n",
    "            # state_dict = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n",
    "            torch.save(save_checkpoint, '{}/model_latest.pth'.format(args.outf))\n",
    "            if is_train_best:\n",
    "                torch.save(save_checkpoint, '{}/model_train_best.pth'.format(args.outf))\n",
    "\n",
    "    print(\"Training complete in: \" + str(datetime.now() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siren",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

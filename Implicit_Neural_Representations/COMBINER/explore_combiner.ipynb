{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, pi\n",
    "import numpy as np\n",
    "\n",
    "import imageio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "\n",
    "\n",
    "def SmoothStd(std):\n",
    "    return F.softplus(std, beta=1, threshold=20)\n",
    "\n",
    "\n",
    "def gaussian_analytical_kl(mu1, mu2, sigma1, sigma2, eps=1e-10):\n",
    "    sigma1 = sigma1 + eps\n",
    "    sigma2 = sigma2 + eps\n",
    "    kl = - 0.5 + torch.log(sigma2) - torch.log(sigma1) + 0.5 * (sigma1 ** 2 + (mu1 - mu2) ** 2) / (sigma2 ** 2)\n",
    "    return F.relu(kl)\n",
    "\n",
    "\n",
    "class Sine(nn.Module):\n",
    "    \"\"\"Sine activation with scaling.\n",
    "    Args:\n",
    "        w0 (float): Omega_0 parameter from Siren paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, w0=1.):\n",
    "        super().__init__()\n",
    "        self.w0 = w0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.w0 * x)\n",
    "    \n",
    "\n",
    "class VarSirenLayer(nn.Module):\n",
    "    \"\"\" variational Bayesian Siren layer.\n",
    "    Args:\n",
    "        dim_in: the input dimension of this layer.\n",
    "        dim_out: the output dimension of this layer.\n",
    "        std_init: the initializations of std.\n",
    "        is_first: we empirically adjust the initialization of variance.\n",
    "        w0 and c are parameters from Siren paper.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        dim_in, \n",
    "        dim_out, \n",
    "        std_init, \n",
    "        is_first,\n",
    "        w0=30., \n",
    "        c=6., \n",
    "        activation=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_out = dim_out\n",
    "\n",
    "        # initialization in original Siren model.\n",
    "        w_std = (1 / dim_in) if is_first else (sqrt(c / dim_in) / w0)\n",
    "        self.w_std = w_std\n",
    "\n",
    "        # the variance may influence the training stability, so the initialization of mu is empirically adjusted.\n",
    "        self.mu = nn.Parameter(torch.FloatTensor(dim_in + 1, dim_out).uniform_(- w_std / 12 * 11, w_std / 12 * 11))\n",
    "        self.std = nn.Parameter(torch.FloatTensor(dim_in + 1, dim_out).fill_(std_init))\n",
    "\n",
    "        # no activation for the last layer.\n",
    "        self.activation = Sine(w0) if activation is None else activation\n",
    "\n",
    "    def forward(self, x, mu_prior, std_prior, mask=None, yhat=None):\n",
    "        if mask is None:\n",
    "            mask, yhat = 0, 0\n",
    "            \n",
    "        mu = self.mu * (1 - mask) + yhat * mask\n",
    "        std = SmoothStd(self.std)\n",
    "        std = std * (1 - mask) + 1e-7 * mask\n",
    "\n",
    "        mu_w_q, mu_b_q, std_w_q, std_b_q = mu[:-1], mu[-1], std[:-1], std[-1]\n",
    "\n",
    "        # local reparameterization trick\n",
    "        act_w_mu = torch.mm(x, mu_w_q)  \n",
    "        act_w_std = torch.sqrt(torch.mm(x.pow(2), std_w_q.pow(2)) + 1e-14)\n",
    "\n",
    "        kld_w = gaussian_analytical_kl(mu_w_q, mu_prior[:-1], std_w_q, std_prior[:-1])\n",
    "        print('mu_w.shape: ', mu_w_q.shape)\n",
    "        print('kld_w.shape: ', kld_w.shape)\n",
    "        kld_b = gaussian_analytical_kl(mu_b_q, mu_prior[-1], std_b_q, std_prior[-1])        \n",
    "        eps_w = torch.empty_like(act_w_mu).normal_(0., 1.).to(x.dtype)\n",
    "        eps_b = torch.empty_like(std_b_q).normal_(0., 1.).to(x.dtype)\n",
    "        act_w_out = act_w_mu + act_w_std * eps_w  # (batch_size, n_output)\n",
    "        act_b_out = mu_b_q + std_b_q * eps_b\n",
    "        out = act_w_out + act_b_out\n",
    "\n",
    "        out = self.activation(out)\n",
    "        kld_cat = torch.cat([kld_w, kld_b.unsqueeze(0)], dim=0) * (1 - mask)\n",
    "        return out, kld_cat\n",
    "\n",
    "\n",
    "class SirenPosterior(nn.Module):\n",
    "    \"\"\" variational posterior of Siren model.\n",
    "    Args:\n",
    "        dim_in: the output dimension (2 on image dataset).\n",
    "        dim_out: the output dimension (3 on image dataset).\n",
    "        dim_emb: the input dimension of the siren model after Fourier embedding.\n",
    "        dim_hid: the hidden unit dimension.\n",
    "        num_layers: the number of linear layers.\n",
    "        std_init: we empirically adjust the initialization of variance.\n",
    "        w0 is a parameter from Siren paper.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        dim_in,\n",
    "        dim_emb, \n",
    "        dim_hid, \n",
    "        dim_out, \n",
    "        num_layers, \n",
    "        std_init, \n",
    "        w0=30.,\n",
    "        c=6.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_emb = dim_emb\n",
    "        layers = []\n",
    "        for ind in range(num_layers):\n",
    "            layers.append(VarSirenLayer(\n",
    "                dim_in = dim_emb if ind == 0 else dim_hid, \n",
    "                dim_out = dim_out if ind == (num_layers - 1) else dim_hid, \n",
    "                std_init = std_init,\n",
    "                is_first = True if ind == 0 else False, \n",
    "                w0 = w0, \n",
    "                c = c,\n",
    "                activation = nn.Identity() if ind == num_layers - 1 else None, \n",
    "            ))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, model_prior, mask_list=None, yhat_list=None, training=True):\n",
    "        x = self.convert_posenc(x)\n",
    "        kld_list = []\n",
    "        for ind, layer in enumerate(self.net):\n",
    "            x, kld_cat = layer(\n",
    "                x, \n",
    "                mu_prior = model_prior.prior_mu[ind], \n",
    "                std_prior = model_prior.prior_std[ind],\n",
    "                mask = None if mask_list is None else mask_list[ind], \n",
    "                yhat = None if yhat_list is None else yhat_list[ind]\n",
    "            )\n",
    "            kld_list.append(kld_cat)\n",
    "        return x, kld_list\n",
    "\n",
    "    def convert_posenc(self, x):\n",
    "        assert self.dim_emb % (2 * self.dim_in) == 0, \"Embedding size must be the integer multiple of 2 * self.dim_in!\"\n",
    "        w = torch.exp(torch.linspace(0, np.log(1024), self.dim_emb // (2 * self.dim_in), device=x.device))\n",
    "        x = torch.matmul(x.unsqueeze(-1), w.unsqueeze(0)).view(*x.shape[:-1], -1)\n",
    "        x = torch.cat([torch.cos(pi * x), torch.sin(pi * x)], dim=-1)\n",
    "        return x\n",
    "\n",
    "class SirenPrior(nn.Module):\n",
    "    \"\"\" Siren Model Prior.\n",
    "    Args:\n",
    "        dim_emb: the input dimension of the siren model after Fourier embedding.\n",
    "        dim_hid: the hidden unit dimension.\n",
    "        dim_out: the output dimension (3 on image dataset).\n",
    "        num_layers: the number of linear layers.\n",
    "        init_std_scale: we empirically adjust the initialization of variance.\n",
    "        w0 and c are parameters from Siren paper.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        dim_emb, \n",
    "        dim_hid, \n",
    "        dim_out, \n",
    "        num_layers, \n",
    "        init_std_scale=0.5, \n",
    "        w0=30., \n",
    "        c=6.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim_emb = dim_emb\n",
    "        self.prior_mu = nn.ParameterList()\n",
    "        self.prior_std = nn.ParameterList()\n",
    "\n",
    "        for ind in range(num_layers):\n",
    "            # Empirically set the inialization of model prior according to original SIREN.\n",
    "            layer_dim_in = dim_emb if ind == 0 else dim_hid\n",
    "            layer_dim_out = dim_out if ind == (num_layers - 1) else dim_hid\n",
    "            w_std = (1 / dim_emb) if ind == 0 else (sqrt(c / layer_dim_in) / w0)\n",
    "\n",
    "            std = w_std * init_std_scale \n",
    "            self.prior_mu.append(nn.Parameter(torch.zeros([layer_dim_in + 1, layer_dim_out])))\n",
    "            self.prior_std.append(nn.Parameter(torch.ones(layer_dim_in + 1, layer_dim_out) * std))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prior = SirenPrior(\n",
    "                dim_emb=64,\n",
    "                dim_hid=48,\n",
    "                num_layers=6,\n",
    "                init_std_scale=0.5,\n",
    "                dim_out=3,\n",
    "                w0=30.0,\n",
    "                c=6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m3/gc3jv3513p9b_6y82p_46vmw0000gn/T/ipykernel_80819/1403204030.py:12: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread('kodim01.png')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([393216, 2]), torch.Size([393216, 3]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "model = SirenPosterior(\n",
    "    dim_in=2,\n",
    "    dim_emb=64,\n",
    "    dim_hid=48,\n",
    "    dim_out=3,\n",
    "    num_layers=6,\n",
    "    std_init=-10.0,\n",
    "    c=6.0)\n",
    "\n",
    "# load image\n",
    "img = imageio.imread('kodim01.png')\n",
    "img = ToTensor()(img).float()\n",
    "\n",
    "# make coord grid\n",
    "l_lst = []\n",
    "vrange = (-1, 1)\n",
    "for i, s in enumerate(img.shape[1:]):\n",
    "    l = (0.5 + torch.arange(s)) / s\n",
    "    if isinstance(vrange[0], list) or isinstance(vrange[0], tuple):\n",
    "        minv, maxv = vrange[i]\n",
    "    else:\n",
    "        minv, maxv = vrange\n",
    "    l = minv + (maxv - minv) * l\n",
    "    l_lst.append(l)\n",
    "grid = torch.meshgrid(*l_lst, indexing='ij')\n",
    "grid = torch.stack(grid, dim=-1)\n",
    "\n",
    "coords = grid.view(-1, 2)\n",
    "features = img.reshape(img.shape[0], -1).T\n",
    "\n",
    "coords.shape, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([98304, 2]), torch.Size([98304, 3]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = features.shape[0]\n",
    "index = torch.randperm(n)[:n//4]\n",
    "coords = torch.index_select(coords, 0, index)\n",
    "features = torch.index_select(features, 0, index)\n",
    "coords.shape, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    mu_w.shape:  torch.Size([64, 48])\n",
      "kld_w.shape:  torch.Size([64, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 3])\n",
      "kld_w.shape:  torch.Size([48, 3])\n",
      "tensor(63305.3477, grad_fn=<AddBackward0>) tensor(0.1619, grad_fn=<MseLossBackward0>) tensor(0.0317, grad_fn=<MulBackward0>)\n",
      "tensor(0.1935, grad_fn=<AddBackward0>)\n",
      "1    mu_w.shape:  torch.Size([64, 48])\n",
      "kld_w.shape:  torch.Size([64, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 3])\n",
      "kld_w.shape:  torch.Size([48, 3])\n",
      "tensor(63282.5430, grad_fn=<AddBackward0>) tensor(0.1532, grad_fn=<MseLossBackward0>) tensor(0.0316, grad_fn=<MulBackward0>)\n",
      "2    mu_w.shape:  torch.Size([64, 48])\n",
      "kld_w.shape:  torch.Size([64, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 3])\n",
      "kld_w.shape:  torch.Size([48, 3])\n",
      "tensor(63260.6211, grad_fn=<AddBackward0>) tensor(0.1442, grad_fn=<MseLossBackward0>) tensor(0.0316, grad_fn=<MulBackward0>)\n",
      "3    mu_w.shape:  torch.Size([64, 48])\n",
      "kld_w.shape:  torch.Size([64, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 48])\n",
      "kld_w.shape:  torch.Size([48, 48])\n",
      "mu_w.shape:  torch.Size([48, 3])\n",
      "kld_w.shape:  torch.Size([48, 3])\n",
      "tensor(63238.9883, grad_fn=<AddBackward0>) tensor(0.1353, grad_fn=<MseLossBackward0>) tensor(0.0316, grad_fn=<MulBackward0>)\n",
      "4    mu_w.shape:  torch.Size([64, 48])\n",
      "kld_w.shape:  torch.Size([64, 48])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m predicted, kld_list \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_prior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m loss_mse \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()(predicted, features)\n\u001b[1;32m      9\u001b[0m loss_kl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([kld_layer\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;28;01mfor\u001b[39;00m kld_layer \u001b[38;5;129;01min\u001b[39;00m kld_list])\n",
      "File \u001b[0;32m~/miniconda3/envs/siren/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/siren/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 141\u001b[0m, in \u001b[0;36mSirenPosterior.forward\u001b[0;34m(self, x, model_prior, mask_list, yhat_list, training)\u001b[0m\n\u001b[1;32m    139\u001b[0m kld_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet):\n\u001b[0;32m--> 141\u001b[0m     x, kld_cat \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmu_prior\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_prior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior_mu\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstd_prior\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_prior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior_std\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmask_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmask_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43myhat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myhat_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myhat_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     kld_list\u001b[38;5;241m.\u001b[39mappend(kld_cat)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, kld_list\n",
      "File \u001b[0;32m~/miniconda3/envs/siren/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/siren/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 82\u001b[0m, in \u001b[0;36mVarSirenLayer.forward\u001b[0;34m(self, x, mu_prior, std_prior, mask, yhat)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# local reparameterization trick\u001b[39;00m\n\u001b[1;32m     81\u001b[0m act_w_mu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(x, mu_w_q)  \n\u001b[0;32m---> 82\u001b[0m act_w_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_w_q\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-14\u001b[39;49m)\n\u001b[1;32m     84\u001b[0m kld_w \u001b[38;5;241m=\u001b[39m gaussian_analytical_kl(mu_w_q, mu_prior[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], std_w_q, std_prior[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmu_w.shape: \u001b[39m\u001b[38;5;124m'\u001b[39m, mu_w_q\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "num_iters = 400\n",
    "\n",
    "for step in range(num_iters):\n",
    "    print(f'\\r{step}', end='    ')\n",
    "    optimizer.zero_grad()\n",
    "    predicted, kld_list = model(coords, model_prior)\n",
    "    loss_mse = torch.nn.MSELoss()(predicted, features)\n",
    "    loss_kl = sum([kld_layer.sum() for kld_layer in kld_list])\n",
    "    print(loss_kl, loss_mse, loss_kl * 5e-7)\n",
    "    loss = loss_mse + loss_kl * 5e-7\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if not step % 40:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siren",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
